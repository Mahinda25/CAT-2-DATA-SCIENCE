{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZz/qInQyN1QxnuTJhH2h1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahinda25/CAT-2-DATA-SCIENCE/blob/main/CAT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries."
      ],
      "metadata": {
        "id": "hCdpgYRp24UV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z3CDzUnqrYQ",
        "outputId": "330a7c3c-2e57-439e-fea3-ad91eedc0069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your datasets."
      ],
      "metadata": {
        "id": "1YwXskK-0MsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the directory containing the CSV files\n",
        "directory_path = '/content/Election_strategy/'\n",
        "\n",
        "# Get a list of all CSV files in the directory\n",
        "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
        "\n",
        "# Create a dictionary to store DataFrames\n",
        "dfs = {}\n",
        "\n",
        "# Loop through each CSV file and read it\n",
        "for csv_file in csv_files:\n",
        "    file_path = os.path.join(directory_path, csv_file)\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        dfs[csv_file] = df  # Store the DataFrame in the dictionary\n",
        "        print(f\"Shape of the dataset in {csv_file}: {df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found at path: {file_path}\")\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"The CSV file {csv_file} is empty.\")\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"Error while parsing the CSV file {csv_file}.\")\n",
        "\n",
        "# Now, you can access each DataFrame using its corresponding file name\n",
        "# For example, to access the DataFrame for 'ordered_dc_draino.csv':\n",
        "if 'ordered_dc_draino.csv' in dfs:\n",
        "    df_ordered_dc_draino = dfs['ordered_dc_draino.csv']\n",
        "    # Do further processing or analysis with df_ordered_dc_draino\n",
        "    print(df_ordered_dc_draino.head())\n",
        "else:\n",
        "    print(\"DataFrame for 'ordered_dc_draino.csv' not found.\")\n",
        "# For example, to access the DataFrame for 'dataset.csv':\n",
        "if 'dataset.csv' in dfs:\n",
        "    df_dataset = dfs['dataset.csv']\n",
        "    # Do further processing or analysis with df_dataset\n",
        "    print(df_dataset.head())\n",
        "else:\n",
        "    print(\"DataFrame for 'dataset.csv' not found.\")\n",
        "# For example, to access the DataFrame for 'ExtractedTweets.csv':\n",
        "if 'ExtractedTweets.csv' in dfs:\n",
        "    df_ExtractedTweets = dfs['ExtractedTweets.csv']\n",
        "    # Do further processing or analysis with df_ExtractedTweets\n",
        "    print(df_ExtractedTweets.head())\n",
        "else:\n",
        "    print(\"DataFrame for 'dataset.csv' not found.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrNPdLTM0fcr",
        "outputId": "bfc0c0cf-5d4a-4d97-a63b-d556157deb36"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset in ordered_dc_draino.csv: (301, 20)\n",
            "Shape of the dataset in ExtractedTweets.csv: (86461, 4)\n",
            "Shape of the dataset in musae_facebook_target.csv: (5604, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-146-ecaa4baa60ef>:17: DtypeWarning: Columns (0,3,4,5,6,7,9,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,418,420,422,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,586,587,588,589,590,602,603,604,605,606,607,608,609,610,611,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,633,634,636,637,639,640,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset in VOTER_Survey_December16_Release1.csv: (8000, 669)\n",
            "Shape of the dataset in dataset.csv: (2514, 11)\n",
            "Shape of the dataset in TwitterHandles.csv: (48, 5)\n",
            "          ID    Unnamed: 1 comments_disabled                       dimensions  \\\n",
            "0  user00001    __typename             False    {'height': 800, 'width': 640}   \n",
            "1  user00002    GraphVideo             False  {'height': 1335, 'width': 1080}   \n",
            "2  user00003    GraphImage             False  {'height': 1349, 'width': 1080}   \n",
            "3  user00004  GraphSidecar             False  {'height': 1080, 'width': 1080}   \n",
            "4  user00005    GraphImage             False  {'height': 1140, 'width': 1080}   \n",
            "\n",
            "                                         display_url  edge_media_preview_like  \\\n",
            "0  https://scontent-lax3-1.cdninstagram.com/v/t51...                 280008.0   \n",
            "1  https://scontent-lax3-1.cdninstagram.com/v/t51...                 274379.0   \n",
            "2  https://scontent-lax3-1.cdninstagram.com/v/t51...                 254029.0   \n",
            "3  https://scontent-lax3-1.cdninstagram.com/v/t51...                 253498.0   \n",
            "4  https://scontent-lax3-1.cdninstagram.com/v/t51...                 240053.0   \n",
            "\n",
            "                               edge_media_to_caption  edge_media_to_comment  \\\n",
            "0  Footage from Trump Hotel in DC. He may not be ...                 5675.0   \n",
            "1  This got me in the feels. Thank you President ...                 4130.0   \n",
            "2  If Biden can make a fake â€œOffice of the Presid...                 5457.0   \n",
            "3                                Friendly reminderðŸ‡ºðŸ‡¸                 3380.0   \n",
            "4    Good job blue states. Happy?ðŸ‡ºðŸ‡¸PC: @bennyjohnson                 4805.0   \n",
            "\n",
            "  gating_info            id is_video  \\\n",
            "0         NaN  2.492420e+18     True   \n",
            "1         NaN  2.490510e+18    False   \n",
            "2         NaN  2.494770e+18    False   \n",
            "3         NaN  2.515050e+18    False   \n",
            "4         NaN  2.492330e+18    False   \n",
            "\n",
            "                                       media_preview         owner  \\\n",
            "0  ACEq070pvVWZkOONvQ8nrVYtGVJ8xwMLyAfzHPfv+tNvJ5...  4.331071e+09   \n",
            "1  ACIq3LqUou0KzbwR8vUf/X54rMCkoOJflY9+TlV68c+3vm...  4.331071e+09   \n",
            "2                                                NaN  4.331071e+09   \n",
            "3  ACoq5qkq7bNEAd5wee1Ec6qpX5CpYkBlJPb0/wA9aYilRV...  4.331071e+09   \n",
            "4                                                NaN  4.331071e+09   \n",
            "\n",
            "     shortcode tags taken_at_timestamp  \\\n",
            "0  CKW2WdlBF7L   []    1/22/2021 18:18   \n",
            "1  CKQEua_BJWR   []     1/20/2021 3:08   \n",
            "2  CKfNt2qhfqb   []     1/26/2021 0:15   \n",
            "3  CLnPPA1hr2T   []    2/22/2021 23:34   \n",
            "4  CKWhYffB0GJ   []    1/22/2021 15:14   \n",
            "\n",
            "                                       thumbnail_src  \\\n",
            "0  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
            "1  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
            "2  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
            "3  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
            "4  https://scontent-lax3-1.cdninstagram.com/v/t51...   \n",
            "\n",
            "                                                urls   username  \\\n",
            "0  https://scontent-lax3-2.cdninstagram.com/v/t50...  dc_draino   \n",
            "1  https://scontent-lax3-1.cdninstagram.com/v/t51...  dc_draino   \n",
            "2  https://scontent-lax3-1.cdninstagram.com/v/t51...  dc_draino   \n",
            "3  https://scontent-lax3-1.cdninstagram.com/v/t51...  dc_draino   \n",
            "4  https://scontent-lax3-1.cdninstagram.com/v/t51...  dc_draino   \n",
            "\n",
            "   video_view_count  \n",
            "0          882302.0  \n",
            "1               NaN  \n",
            "2               NaN  \n",
            "3               NaN  \n",
            "4               NaN  \n",
            "          ID                Name Twitter_username    Account_start_time  \\\n",
            "0  User00001  A. Donald McEachin      RepMcEachin  2017-01-03T00:00:00Z   \n",
            "1  User00002    Aaron Michlewitz    RepMichlewitz  2010-06-27T00:00:00Z   \n",
            "2  User00003        Aaron Peskin      AaronPeskin  2010-11-13T00:00:00Z   \n",
            "3  User00004          Aaron PeÃ±a        AaronPena  2007-10-31T00:00:00Z   \n",
            "4  User00005        Aaron Schock      aaronschock  2009-03-12T00:00:00Z   \n",
            "\n",
            "  Account_ID   Sex                Birthplace              Birthday   Age  \\\n",
            "0   8.16E+17  male                   Germany  1961-10-10T00:00:00Z  59.0   \n",
            "1  160246973  male  United States of America  1978-01-01T00:00:00Z  42.0   \n",
            "2  215369273  male  United States of America  1964-06-17T00:00:00Z  56.0   \n",
            "3    9843332  male  United States of America  1959-06-08T00:00:00Z  61.0   \n",
            "4   23951197  male  United States of America  1981-05-28T00:00:00Z  39.0   \n",
            "\n",
            "  Instagram_username   Political_party  \n",
            "0        repmceachin  Democratic Party  \n",
            "1                NaN  Democratic Party  \n",
            "2          apeskin52  Democratic Party  \n",
            "3                NaN  Republican Party  \n",
            "4        aaronschock  Republican Party  \n",
            "          ID Political_party         Handle  \\\n",
            "0  User00001        Democrat  RepDarrenSoto   \n",
            "1  User00002        Democrat  RepDarrenSoto   \n",
            "2  User00003        Democrat  RepDarrenSoto   \n",
            "3  User00004        Democrat  RepDarrenSoto   \n",
            "4  User00005        Democrat  RepDarrenSoto   \n",
            "\n",
            "                                               Tweet  \n",
            "0  Today, Senate Dems vote to #SaveTheInternet. P...  \n",
            "1  RT @WinterHavenSun: Winter Haven resident / Al...  \n",
            "2  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...  \n",
            "3  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...  \n",
            "4  RT @Vegalteno: Hurricane season starts on June...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Dataset into Training and Testing Sets"
      ],
      "metadata": {
        "id": "bIkAqQiD4Lvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'musae_facebook_target.csv' contains the target variable\n",
        "target_file = 'musae_facebook_target.csv'\n",
        "\n",
        "# Check if the target file is in the loaded DataFrames\n",
        "if target_file in dfs:\n",
        "    target_df = dfs[target_file]\n",
        "\n",
        "    # Assuming 'user_id' is a common column for merging\n",
        "    merged_data = pd.merge(df_dataset, target_df, on='ID')\n",
        "\n",
        "    # Assuming 'target_column' is the column representing the target variable\n",
        "    X = merged_data.drop('Political_party', axis=1)  # Features\n",
        "    y = merged_data['Political_party']  # Target variable\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f'Shape of X_train: {X_train.shape}, Shape of X_test: {X_test.shape}')\n",
        "    print(f'Shape of y_train: {y_train.shape}, Shape of y_test: {y_test.shape}')\n",
        "else:\n",
        "    print(f\"Target DataFrame '{target_file}' not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGjQWmefgkG9",
        "outputId": "4b866d00-c60c-4475-9049-433d20fc8fb1"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (2011, 13), Shape of X_test: (503, 13)\n",
            "Shape of y_train: (2011,), Shape of y_test: (503,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names in df_dataset and target_df\n",
        "print(df_dataset.columns)\n",
        "print(target_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igzDCy_nyaBS",
        "outputId": "6e334402-1903-413e-993b-9a7b46fccc59"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Name', 'Twitter_username', 'Account_start_time', 'Account_ID',\n",
            "       'Sex', 'Birthplace', 'Birthday', 'Age', 'Instagram_username',\n",
            "       'Political_party'],\n",
            "      dtype='object')\n",
            "Index(['ID', 'facebook_id', 'page_name', 'page_type'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Random Forest Classifier"
      ],
      "metadata": {
        "id": "oefRSxargyRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Assuming 'y' is a numpy array\n",
        "y = pd.Series(y)\n",
        "\n",
        "# Remove rows where 'ID' is equal to 'Vicente GonzÃ¡lez'\n",
        "X_cleaned = X[X['ID'] != ID_to_remove]\n",
        "y_cleaned = y.loc[X_cleaned.index]\n",
        "\n",
        "# Assuming 'ID' is the column containing 'Vicente GonzÃ¡lez'\n",
        "ID_to_remove = 'Victor Escobar'\n",
        "\n",
        "# Remove rows where 'ID' is equal to 'Vicente GonzÃ¡lez'\n",
        "X_cleaned = X[X['ID'] != ID_to_remove]\n",
        "y_cleaned = y.loc[X_cleaned.index]  # Adjust y accordingly\n",
        "\n",
        "# Use one-hot encoding for categorical variables\n",
        "X_encoded_cleaned = pd.get_dummies(X_cleaned, columns=['ID'])\n",
        "\n",
        "# Split the cleaned dataset into training and testing sets\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
        "    X_encoded_cleaned, y_cleaned, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Check data types and null values\n",
        "print(X_train_cleaned.info())\n",
        "print(X_test_cleaned.info())\n",
        "\n",
        "# Check column names\n",
        "print(X_train_cleaned.columns)\n",
        "print(X_test_cleaned.columns)\n",
        "\n",
        "# Create Decision Tree model\n",
        "dt_model_cleaned = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model and make predictions\n",
        "try:\n",
        "    dt_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
        "    dt_predictions_cleaned = dt_model_cleaned.predict(X_test_cleaned)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4gC-Ivx6Vei",
        "outputId": "d23deabf-6aca-40f3-d6e4-b5881510622b"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2011 entries, 2460 to 860\n",
            "Columns: 2526 entries, Name to ID_User02515\n",
            "dtypes: float64(2), object(10), uint8(2514)\n",
            "memory usage: 5.0+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 503 entries, 617 to 1467\n",
            "Columns: 2526 entries, Name to ID_User02515\n",
            "dtypes: float64(2), object(10), uint8(2514)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "Index(['Name', 'Twitter_username', 'Account_start_time', 'Account_ID', 'Sex',\n",
            "       'Birthplace', 'Birthday', 'Age', 'Instagram_username', 'facebook_id',\n",
            "       ...\n",
            "       'ID_User02506', 'ID_User02507', 'ID_User02508', 'ID_User02509',\n",
            "       'ID_User02510', 'ID_User02511', 'ID_User02512', 'ID_User02513',\n",
            "       'ID_User02514', 'ID_User02515'],\n",
            "      dtype='object', length=2526)\n",
            "Index(['Name', 'Twitter_username', 'Account_start_time', 'Account_ID', 'Sex',\n",
            "       'Birthplace', 'Birthday', 'Age', 'Instagram_username', 'facebook_id',\n",
            "       ...\n",
            "       'ID_User02506', 'ID_User02507', 'ID_User02508', 'ID_User02509',\n",
            "       'ID_User02510', 'ID_User02511', 'ID_User02512', 'ID_User02513',\n",
            "       'ID_User02514', 'ID_User02515'],\n",
            "      dtype='object', length=2526)\n",
            "Error: could not convert string to float: 'Victor escobar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'y' is a numpy array\n",
        "y = pd.Series(y)\n",
        "\n",
        "# Assuming 'ID' is the column containing 'Victor Escobar'\n",
        "ID_to_remove = 'Victor Escobar'\n",
        "\n",
        "# Remove rows where 'ID' is equal to 'Victor Escobar'\n",
        "X_cleaned = X[X['ID'] != ID_to_remove]\n",
        "y_cleaned = y.loc[X_cleaned.index]\n",
        "\n",
        "# Use one-hot encoding for categorical variables\n",
        "X_encoded_cleaned = pd.get_dummies(X_cleaned, columns=['ID'])\n",
        "\n",
        "# Split the cleaned dataset into training and testing sets\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
        "    X_encoded_cleaned, y_cleaned, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Check data types and null values\n",
        "print(X_train_cleaned.info())\n",
        "print(X_test_cleaned.info())\n",
        "\n",
        "# Check column names\n",
        "print(X_train_cleaned.columns)\n",
        "print(X_test_cleaned.columns)\n",
        "\n",
        "# Create Random Forest model\n",
        "rf_model_cleaned = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model and make predictions\n",
        "try:\n",
        "    rf_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
        "    rf_predictions_cleaned = rf_model_cleaned.predict(X_test_cleaned)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "id": "9n9W1DxXKdfx",
        "outputId": "57c25093-3601-40ef-ebbc-5137ef6bf87b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2011 entries, 2460 to 860\n",
            "Columns: 2526 entries, Name to ID_User02515\n",
            "dtypes: float64(2), object(10), uint8(2514)\n",
            "memory usage: 5.0+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 503 entries, 617 to 1467\n",
            "Columns: 2526 entries, Name to ID_User02515\n",
            "dtypes: float64(2), object(10), uint8(2514)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "Index(['Name', 'Twitter_username', 'Account_start_time', 'Account_ID', 'Sex',\n",
            "       'Birthplace', 'Birthday', 'Age', 'Instagram_username', 'facebook_id',\n",
            "       ...\n",
            "       'ID_User02506', 'ID_User02507', 'ID_User02508', 'ID_User02509',\n",
            "       'ID_User02510', 'ID_User02511', 'ID_User02512', 'ID_User02513',\n",
            "       'ID_User02514', 'ID_User02515'],\n",
            "      dtype='object', length=2526)\n",
            "Index(['Name', 'Twitter_username', 'Account_start_time', 'Account_ID', 'Sex',\n",
            "       'Birthplace', 'Birthday', 'Age', 'Instagram_username', 'facebook_id',\n",
            "       ...\n",
            "       'ID_User02506', 'ID_User02507', 'ID_User02508', 'ID_User02509',\n",
            "       'ID_User02510', 'ID_User02511', 'ID_User02512', 'ID_User02513',\n",
            "       'ID_User02514', 'ID_User02515'],\n",
            "      dtype='object', length=2526)\n",
            "Error: could not convert string to float: 'Victor escobar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the trained model to make predictions on the test data."
      ],
      "metadata": {
        "id": "k7WrkeG34QzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "X = merged_data.drop('Political_party', axis=1)  # Features\n",
        "y = merged_data['Political_party']  # Target variable\n",
        "\n",
        "# Use LabelEncoder to convert string labels to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "9Nd-sEzkAPKI"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'merged_data' is the original dataset\n",
        "X_test_data = merged_data.drop('Political_party', axis=1)\n",
        "\n",
        "# Use LabelEncoder to convert string labels to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_test_data = label_encoder.fit_transform(merged_data['Political_party'])\n",
        "\n",
        "# Use one-hot encoding for categorical variables\n",
        "X_test_data_encoded = pd.get_dummies(X_test_data, columns=['ID'])\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "try:\n",
        "    rf_predictions_test = rf_model_cleaned.predict(X_test_data_encoded)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(rf_predictions_test)\n",
        "\n",
        "# Now you can use 'predicted_labels' for further analysis or evaluation\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "id": "JA4MXTdWK_Xc",
        "outputId": "48bd494c-a768-4079-9a9b-23a752305ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: could not convert string to float: 'A. Donald McEachin'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-1c99a48fa16b>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Convert numeric predictions back to original labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_predictions_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Now you can use 'predicted_labels' for further analysis or evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rf_predictions_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ],
      "metadata": {
        "id": "CCNbq9dN4Ztk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation"
      ],
      "metadata": {
        "id": "QehjV_944go1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-Nvv6h-Bg5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}